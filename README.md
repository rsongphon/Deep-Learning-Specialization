# Deep-Learning-Specialization

## This Repository is use for educational purpose and reference only! Please try to apply the assigntment by yourself first!

My solution for this couse and also use for review by myself. 

for anyone whos interest in this couse here's the info.

## About this course 

The Deep Learning Specialization is a foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. 

In this Specialization, you will build and train neural network architectures such as Convolutional Neural Networks, Recurrent Neural Networks, LSTMs, Transformers, and learn how to make them better with strategies such as Dropout, BatchNorm, Xavier/He initialization, and more. Get ready to master theoretical concepts and their industry applications using Python and TensorFlow and tackle real-world cases such as speech recognition, music synthesis, chatbots, machine translation, natural language processing, and more.

AI is transforming many industries. The Deep Learning Specialization provides a pathway for you to take the definitive step in the world of AI by helping you gain the knowledge and skills to level up your career. Along the way, you will also get career advice from deep learning experts from industry and academia.

Applied Learning Project
By the end you’ll be able to

 • Build and train deep neural networks, implement vectorized neural networks, identify architecture parameters, and apply DL to your applications

• Use best practices to train and develop test sets and analyze bias/variance for building DL applications, use standard NN techniques, apply optimization algorithms, and implement a neural network in TensorFlow

• Use strategies for reducing errors in ML systems, understand complex ML settings, and apply end-to-end, transfer, and multi-task learning

• Build a Convolutional Neural Network, apply it to visual detection and recognition tasks, use neural style transfer to generate art, and apply these algorithms to image, video, and other 2D/3D data

• Build and train Recurrent Neural Networks and its variants (GRUs, LSTMs), apply RNNs to character-level language modeling, work with NLP and Word Embeddings, and use HuggingFace tokenizers and transformers to perform Named Entity Recognition and Question Answering

## Syllabus

* Course 1: Neural Networks and Deep Learning
In the first course of the Deep Learning Specialization, you will study the foundational concept of neural networks and deep learning.

By the end, you will be familiar with the significant technological trends driving the rise of deep learning; build, train, and apply fully connected deep neural networks; implement efficient (vectorized) neural networks; identify key parameters in a neural network’s architecture; and apply deep learning to your own applications.

    * Week 1: Introduction to Deep Learning
    Understand the significant technological trends driving deep learning development and where and how it’s applied.

    * Week 2: Neural Networks Basics
    Set up a machine learning problem with a neural network mindset and use vectorization to speed up your models.

    * Week 3: Shallow Neural Networks
    Build a neural network with one hidden layer using forward propagation and backpropagation.

    * Week 4: Deep Neural Networks
    Understand the key computations underlying deep learning, use them to build and train deep neural networks, and apply them to computer vision.

* Course 2: Improving Deep Neural Networks: Hyperparameter Tuning, Regularization, and Optimization
In the second course of the Deep Learning Specialization, you will open the deep learning black box to understand the processes that drive performance and generate good results systematically.

By the end, you will learn the best practices to train and develop test sets and analyze bias/variance for building deep learning applications; be able to use standard neural network techniques such as initialization, L2 and dropout regularization, hyperparameter tuning, batch normalization, and gradient checking; implement and apply various optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop, and Adam, and check for their convergence; and implement a neural network in TensorFlow.

      * Week 1: Practical Aspects of Deep Learning
      Discover and experiment with various initialization methods, apply L2 regularization and dropout to avoid model overfitting, and use gradient checking to     identify errors in a fraud detection model.

      * Week 2: Optimization Algorithms
      Develop your deep learning toolbox by adding more advanced optimizations, random mini-batching, and learning rate decay scheduling to speed up your models.

      * Week 3: Hyperparameter tuning, Batch Normalization, and Programming Frameworks
      Explore TensorFlow, a deep learning framework that allows you to build neural networks quickly and easily and train a neural network on a TensorFlow dataset.
      
* Course 3: Structuring Machine Learning Projects
In the third course of the Deep Learning Specialization, you will learn how to build a successful machine learning project and get to practice decision-making as a machine learning project leader.

By the end, you will be able to diagnose errors in a machine learning system; prioritize strategies for reducing errors; understand complex ML settings, such as mismatched training/test sets, and comparing to and/or surpassing human-level performance; and apply end-to-end learning, transfer learning, and multi-task learning.

This is also a standalone course for learners who have basic machine learning knowledge. This course draws on Andrew Ng’s experience building and shipping many deep learning products. If you aspire to become a technical leader who can set the direction for an AI team, this course provides the “industry experience” that you might otherwise get only after years of ML work experience.

      * Week 1: ML Strategy (1)
      Use a machine learning flight simulator to learn how machine learning achieves human-level performance.

      * Week 2: ML Strategy (2)
      Become familiar with the concepts of end-to-end learning, transfer learning, and multi-task learning.
      
* Course 4: Convolutional Neural Networks
In the fourth course of the Deep Learning Specialization, you will understand how computer vision has evolved and become familiar with its exciting applications such as autonomous driving, face recognition, reading radiology images, and more.

By the end, you will be able to build a convolutional neural network, including recent variations such as residual networks; apply convolutional networks to visual detection and recognition tasks; and use neural style transfer to generate art and apply these algorithms to a variety of image, video, and other 2D or 3D data.

      * Week 1: Foundations of Convolutional Neural Networks
      Implement the foundational layers of CNNs (pooling, convolutions) and stack them properly in a deep network to solve multi-class image classification problems.

      * Week 2: Deep Convolutional Models: Case Studies
      Discover practical techniques and methods used in research papers to apply transfer learning to your own deep CNN.

      * Week 3: Object Detection
      Apply your knowledge of CNNs to computer vision: object detection and semantic segmentation using self-driving car datasets.

      * Week 4: Special Applications: Face Recognition and Neural Style Transfer
      Discover how CNNs can be applied to multiple fields, including art generation and face recognition, and implement your own algorithm to generate art and recognize faces.
      
* Course 5: Sequence Models
In the fifth course of the Deep Learning Specialization, you will become familiar with sequence models and their exciting applications such as speech recognition, music synthesis, chatbots, machine translation, natural language processing (NLP), and more.

By the end, you will be able to build and train Recurrent Neural Networks (RNNs) and commonly-used variants such as GRUs and LSTMs; apply RNNs to Character-level Language Modeling; gain experience with natural language processing and Word Embeddings; and use HuggingFace tokenizers and transformer models to solve different NLP tasks such as NER and Question Answering.

      * Week 1: Recurrent Neural Networks
      Discover recurrent neural networks (RNNs) and several of their variants, including LSTMs, GRUs and Bidirectional RNNs, all models that perform exceptionally well on temporal data.

      * Week 2: Natural Language Processing and Word Embeddings
      Use word vector representations and embedding layers to train recurrent neural networks with an outstanding performance across a wide variety of applications, including sentiment analysis, named entity recognition, and neural machine translation.

      * Week 3: Sequence Models and the Attention Mechanism
      Augment your sequence models using an attention mechanism, an algorithm that helps your model decide where to focus its attention given a sequence of inputs, explore speech recognition and how to deal with audio data, and improve your sequence models with the attention mechanism.

      * Week 4: Transformers
      Build the transformer architecture and tackle natural language processing (NLP) tasks such as attention models, named entity recognition (NER) and Question Answering (QA).

